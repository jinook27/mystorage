{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LHgRoFWEldM8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.utils as utils\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.metrics as skl\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "#**************************************************\n",
    "#                Data load class\n",
    "#**************************************************\n",
    "\n",
    "# dataset set and data loader\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True)\n",
    "\n",
    "#Visualize\n",
    "def visualizeMNIST(trainset):\n",
    "    datanum = len(trainset)\n",
    "    fig = plt.figure()\n",
    "    ims = np.random.randint(datanum, size=15)\n",
    "\n",
    "    for i in range(15):\n",
    "        subplot = fig.add_subplot(3,5, i+1)\n",
    "        subplot.set_xticks([])\n",
    "        subplot.set_yticks([])\n",
    "        PILimg, label = trainset[ims[i]]\n",
    "        subplot.set_title(\"%d\" %label)\n",
    "        subplot.imshow(PILimg)\n",
    "    plt.show()\n",
    "\n",
    "visualizeMNIST(trainset)\n",
    "\n",
    "\n",
    "#standardization code\n",
    "standardizer = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "\n",
    "# dataset set and data loader\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, transform=standardizer, download=True)\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, transform=standardizer, download=True)\n",
    "\n",
    "\n",
    "#Data Loader\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cyt5ydAIRO4V"
   },
   "outputs": [],
   "source": [
    "#**************************************************\n",
    "#                Initialize\n",
    "#**************************************************\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "epochs = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7oyzptdsmNwb"
   },
   "outputs": [],
   "source": [
    "#**************************************************\n",
    "#                Network\n",
    "#**************************************************\n",
    "# MultiLayerPerceptron\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, 10),\n",
    "            #nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28 * 28)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Model\n",
    "print('==> Building model..')\n",
    "net = MLP()\n",
    "net = net.to(device)\n",
    "\n",
    "if device == 'cuda':\n",
    "    net = torch.nn.DataParallel(net)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "# Loss, Optimizer, Scheduler setting\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s19Q69HvmO2x"
   },
   "outputs": [],
   "source": [
    "#**************************************************\n",
    "#                Training and testing\n",
    "#**************************************************\n",
    "\n",
    "# Training\n",
    "def train(epoch):\n",
    "    print('\\nEpoch: %d' % epoch)\n",
    "    print('\\nTrain:')\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        if batch_idx+1 == len(trainloader):\n",
    "            print('[%3d/%3d] | Loss: %.3f | Acc: %.3f%% (%d/%d)'%(\n",
    "                batch_idx+1, len(trainloader), train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "            \n",
    "      \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Test\n",
    "def test(epoch):\n",
    "    print('\\nTest:')\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "            if batch_idx+1 == len(testloader):\n",
    "                print('[%3d/%3d] | Loss: %.3f | Acc: %.3f%% (%d/%d)'%(\n",
    "                    batch_idx+1, len(testloader), test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    scheduler.step()\n",
    "    for param_group in optimizer.param_groups:\n",
    "        print('Current learning rate is {:f}'.format(param_group['lr']))\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(epoch)\n",
    "    test(epoch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wW90uAU4mSw9"
   },
   "outputs": [],
   "source": [
    "\n",
    "#**************************************************\n",
    "#                Visualize\n",
    "#**************************************************\n",
    "\n",
    "def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "net.eval()\n",
    "\n",
    "ylabel = []\n",
    "yhatlabel = []\n",
    "\n",
    "for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    outputs = net(inputs)\n",
    "    _, predicted = outputs.max(1)\n",
    "    ylabel = np.concatenate((ylabel, targets.cpu().numpy()))\n",
    "    yhatlabel = np.concatenate((yhatlabel, predicted.cpu().numpy()))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = skl.confusion_matrix(ylabel, yhatlabel)\n",
    "np.set_printoptions(precision=2)\n",
    "is_correct = (ylabel == yhatlabel)\n",
    "acc = np.sum(is_correct * 1) / len(is_correct)\n",
    "print('accuracy:%.5f' % acc)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure()\n",
    "name_list = [\"{:1d}\".format(x) for x in range(10)]  # ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "plot_confusion_matrix(cnf_matrix, classes=name_list,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=name_list, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "3_MLP_multiple_pytorch_MNIST.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
